<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Spark HA &amp; Yarné…ç½® | Hexo</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
    
<meta name="generator" content="Hexo 6.2.0"></head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/archives" class="header__link">Archive</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Hexo</a></h1>
		<h2 class="header__subtitle"></h2>
	</header>

	<main>
		<article>
	
		<h1>Spark HA &amp; Yarné…ç½®</h1>
	
	<div class="article__infos">
		<span class="article__date">2022-05-25</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/spark/" rel="tag">spark</a>
			</span>
		
	</div>

	

	
		<p>Welcome to visit!ğŸ¥° If there is any incorrect place in this article, you are welcome to correct it. Beginner onlyğŸ˜</p>
<h2 id="Spark-On-YARNæ¨¡å¼"><a href="#Spark-On-YARNæ¨¡å¼" class="headerlink" title="Spark On YARNæ¨¡å¼"></a>Spark On YARNæ¨¡å¼</h2><p>åœ¨å·²æœ‰YARNé›†ç¾¤çš„å‰æä¸‹åœ¨å•ç‹¬å‡†å¤‡Spark StandAloneé›†ç¾¤,å¯¹èµ„æºçš„åˆ©ç”¨å°±ä¸é«˜.Spark On YARN, æ—  éœ€éƒ¨ç½²Sparké›†ç¾¤, åªè¦æ‰¾ä¸€å°æœåŠ¡å™¨, å……å½“Sparkçš„å®¢æˆ·ç«¯</p>
<h3 id="ä¿è¯-HADOOP-CONF-å’Œ-DIR-YARN-CONF-DIR-å·²ç»é…ç½®åœ¨spark-env-sh-å’Œç¯å¢ƒå˜é‡ä¸­-ï¼ˆæ³¨-å‰é¢é…ç½®spark-Standlone-æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰"><a href="#ä¿è¯-HADOOP-CONF-å’Œ-DIR-YARN-CONF-DIR-å·²ç»é…ç½®åœ¨spark-env-sh-å’Œç¯å¢ƒå˜é‡ä¸­-ï¼ˆæ³¨-å‰é¢é…ç½®spark-Standlone-æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰" class="headerlink" title="ä¿è¯ HADOOP_CONF_å’Œ DIR_YARN_CONF_DIR å·²ç»é…ç½®åœ¨spark-env.sh å’Œç¯å¢ƒå˜é‡ä¸­ ï¼ˆæ³¨: å‰é¢é…ç½®spark-Standlone æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰"></a>ä¿è¯ HADOOP_CONF_å’Œ DIR_YARN_CONF_DIR å·²ç»é…ç½®åœ¨spark-env.sh å’Œç¯å¢ƒå˜é‡ä¸­ ï¼ˆæ³¨: å‰é¢é…ç½®spark-Standlone æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spark-env.sh æ–‡ä»¶éƒ¨åˆ†æ˜¾ç¤ºï¼š</span><br><span class="line">....</span><br><span class="line">77 ## HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤</span><br><span class="line">78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">....</span><br></pre></td></tr></table></figure>

<h3 id="é“¾æ¥åˆ°-YARN-ä¸­ï¼ˆæ³¨-äº¤äº’å¼ç¯å¢ƒ-pyspark-å’Œ-spark-shell-æ— æ³•è¿è¡Œ-clusteræ¨¡å¼ï¼‰"><a href="#é“¾æ¥åˆ°-YARN-ä¸­ï¼ˆæ³¨-äº¤äº’å¼ç¯å¢ƒ-pyspark-å’Œ-spark-shell-æ— æ³•è¿è¡Œ-clusteræ¨¡å¼ï¼‰" class="headerlink" title="é“¾æ¥åˆ° YARN ä¸­ï¼ˆæ³¨: äº¤äº’å¼ç¯å¢ƒ pyspark å’Œ spark-shell æ— æ³•è¿è¡Œ clusteræ¨¡å¼ï¼‰"></a>é“¾æ¥åˆ° YARN ä¸­ï¼ˆæ³¨: äº¤äº’å¼ç¯å¢ƒ pyspark å’Œ spark-shell æ— æ³•è¿è¡Œ clusteræ¨¡å¼ï¼‰</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/pyspark --master yarn --deploy-mode client|cluster</span><br><span class="line"># --deploy-mode é€‰é¡¹æ˜¯æŒ‡å®šéƒ¨ç½²æ¨¡å¼, é»˜è®¤æ˜¯ å®¢æˆ·ç«¯æ¨¡å¼</span><br><span class="line"># clientå°±æ˜¯å®¢æˆ·ç«¯æ¨¡å¼</span><br><span class="line"># clusterå°±æ˜¯é›†ç¾¤æ¨¡å¼</span><br><span class="line"># --deploy-mode ä»…å¯ä»¥ç”¨åœ¨YARNæ¨¡å¼ä¸‹</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master yarn --deploy-mode client|cluster /xxx/xxx/xxx.py</span><br><span class="line">å‚æ•°</span><br></pre></td></tr></table></figure>

<h3 id="spark-submit-å’Œ-spark-shell-å’Œ-pysparkçš„ç›¸å…³å‚æ•°"><a href="#spark-submit-å’Œ-spark-shell-å’Œ-pysparkçš„ç›¸å…³å‚æ•°" class="headerlink" title="spark-submit å’Œ spark-shell å’Œ pysparkçš„ç›¸å…³å‚æ•°"></a>spark-submit å’Œ spark-shell å’Œ pysparkçš„ç›¸å…³å‚æ•°</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- bin/pyspark: pysparkè§£é‡Šå™¨sparkç¯å¢ƒ</span><br><span class="line">- bin/spark-shell: scalaè§£é‡Šå™¨sparkç¯å¢ƒ</span><br><span class="line">- bin/spark-submit: æäº¤jaråŒ…æˆ–Pythonæ–‡ä»¶æ‰§è¡Œçš„å·¥å…·</span><br><span class="line">- bin/spark-sql: sparksqlå®¢æˆ·ç«¯å·¥å…·</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">è¿™4ä¸ªå®¢æˆ·ç«¯å·¥å…·çš„å‚æ•°åŸºæœ¬é€šç”¨.ä»¥spark-submit ä¸ºä¾‹:</span><br><span class="line">bin/spark-submit --master spark://master:7077 xxx.py`</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app</span><br><span class="line">arguments]</span><br><span class="line">Usage: spark-submit --kill [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit --status [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit run-example [options] example-class [example args]</span><br><span class="line">Options:</span><br><span class="line">--master MASTER_URL spark://host:port, mesos://host:port, yarn,</span><br><span class="line">k8s://https://host:port, or local (Default:</span><br><span class="line">local[*]).</span><br><span class="line">--deploy-mode DEPLOY_MODE éƒ¨ç½²æ¨¡å¼ client æˆ–è€… cluster é»˜è®¤æ˜¯client</span><br><span class="line">--class CLASS_NAME è¿è¡Œjavaæˆ–è€…scala class(for Java / Scala apps).</span><br><span class="line">--name NAME ç¨‹åºçš„åå­—</span><br><span class="line">--jars JARS Comma-separated list of jars to include on the</span><br><span class="line">driver</span><br><span class="line">and executor classpaths.</span><br><span class="line">--packages Comma-separated list of maven coordinates of</span><br><span class="line">jars to include</span><br><span class="line">on the driver and executor classpaths. Will</span><br><span class="line">search the local</span><br><span class="line">maven repo, then maven central and any</span><br><span class="line">additional remote</span><br><span class="line">repositories given by --repositories. The</span><br><span class="line">format for the</span><br><span class="line">coordinates should be</span><br><span class="line">groupId:artifactId:version.</span><br><span class="line">--exclude-packages Comma-separated list of groupId:artifactId, to</span><br><span class="line">exclude while</span><br><span class="line">resolving the dependencies provided in --</span><br><span class="line">packages to avoid</span><br><span class="line">dependency conflicts.</span><br><span class="line">--repositories Comma-separated list of additional remote</span><br><span class="line">repositories to</span><br><span class="line">search for the maven coordinates given with --</span><br><span class="line">packages.</span><br><span class="line">--py-files PY_FILES æŒ‡å®šPythonç¨‹åºä¾èµ–çš„å…¶å®ƒpythonæ–‡ä»¶</span><br><span class="line">--files FILES Comma-separated list of files to be placed in</span><br><span class="line">the working</span><br><span class="line">directory of each executor. File paths of</span><br><span class="line">these files</span><br><span class="line">in executors can be accessed via</span><br><span class="line">SparkFiles.get(fileName).</span><br><span class="line">--archives ARCHIVES Comma-separated list of archives to be</span><br><span class="line">extracted into the</span><br><span class="line">working directory of each executor.</span><br><span class="line">--conf, -c PROP=VALUE æ‰‹åŠ¨æŒ‡å®šé…ç½®</span><br><span class="line">--properties-file FILE Path to a file from which to load extra</span><br><span class="line">properties. If not</span><br><span class="line">specified, this will look for conf/sparkdefaults.conf.</span><br><span class="line">--driver-memory MEM Driverçš„å¯ç”¨å†…å­˜(Default: 1024M).</span><br><span class="line">--driver-java-options Driverçš„ä¸€äº›Javaé€‰é¡¹</span><br><span class="line">--driver-library-path Extra library path entries to pass to the</span><br><span class="line">driver.</span><br><span class="line">--driver-class-path Extra class path entries to pass to the</span><br><span class="line">driver. Note that</span><br><span class="line">jars added with --jars are automatically</span><br><span class="line">included in the</span><br><span class="line">classpath.</span><br><span class="line">--executor-memory MEM Executorçš„å†…å­˜ (Default: 1G).</span><br><span class="line">--proxy-user NAME User to impersonate when submitting the</span><br><span class="line">application.</span><br><span class="line">This argument does not work with --principal /</span><br><span class="line">--keytab.</span><br><span class="line">--help, -h æ˜¾ç¤ºå¸®åŠ©æ–‡ä»¶</span><br><span class="line">--verbose, -v Print additional debug output.</span><br><span class="line">--version, æ‰“å°ç‰ˆæœ¬</span><br><span class="line">Cluster deploy mode only(é›†ç¾¤æ¨¡å¼ä¸“å±):</span><br><span class="line">--driver-cores NUM Driverå¯ç”¨çš„çš„CPUæ ¸æ•°(Default: 1).</span><br><span class="line">Spark standalone or Mesos with cluster deploy mode only:</span><br><span class="line">--supervise å¦‚æœç»™å®š, å¯ä»¥å°è¯•é‡å¯Driver</span><br><span class="line">Spark standalone, Mesos or K8s with cluster deploy mode only:</span><br><span class="line">--kill SUBMISSION_ID æŒ‡å®šç¨‹åºID kill</span><br><span class="line">--status SUBMISSION_ID æŒ‡å®šç¨‹åºID æŸ¥çœ‹è¿è¡ŒçŠ¶æ€</span><br><span class="line">Spark standalone, Mesos and Kubernetes only:</span><br><span class="line">--total-executor-cores NUM æ•´ä¸ªä»»åŠ¡å¯ä»¥ç»™Executorå¤šå°‘ä¸ªCPUæ ¸å¿ƒç”¨</span><br><span class="line">Spark standalone, YARN and Kubernetes only:</span><br><span class="line">--executor-cores NUM å•ä¸ªExecutorèƒ½ä½¿ç”¨å¤šå°‘CPUæ ¸å¿ƒ</span><br><span class="line">Spark on YARN and Kubernetes only(YARNæ¨¡å¼ä¸‹):</span><br><span class="line">--num-executors NUM Executoråº”è¯¥å¼€å¯å‡ ä¸ª</span><br><span class="line">--principal PRINCIPAL Principal to be used to login to KDC.</span><br><span class="line">--keytab KEYTAB The full path to the file that contains the</span><br><span class="line">keytab for the</span><br><span class="line">principal specified above.</span><br><span class="line">Spark on YARN only:</span><br><span class="line">--queue QUEUE_NAME æŒ‡å®šè¿è¡Œçš„YARNé˜Ÿåˆ—(Default: &quot;default&quot;).</span><br></pre></td></tr></table></figure>

<h3 id="å¯åŠ¨-YARN-çš„å†å²æœåŠ¡å™¨"><a href="#å¯åŠ¨-YARN-çš„å†å²æœåŠ¡å™¨" class="headerlink" title="å¯åŠ¨ YARN çš„å†å²æœåŠ¡å™¨"></a>å¯åŠ¨ YARN çš„å†å²æœåŠ¡å™¨</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop-3.3.0/sbin</span><br><span class="line">./mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>

<h3 id="è®¿é—®WebUIç•Œé¢"><a href="#è®¿é—®WebUIç•Œé¢" class="headerlink" title="è®¿é—®WebUIç•Œé¢"></a>è®¿é—®WebUIç•Œé¢</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:19888/</span><br></pre></td></tr></table></figure>

<h3 id="client-æ¨¡å¼æµ‹è¯•"><a href="#client-æ¨¡å¼æµ‹è¯•" class="headerlink" title="client æ¨¡å¼æµ‹è¯•"></a>client æ¨¡å¼æµ‹è¯•</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark</span><br><span class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn --deploy-mode client --</span><br><span class="line">driver-memory 512m --executor-memory 512m --num-executors 1 --totalexecutor-cores 2 $&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py 3</span><br></pre></td></tr></table></figure>

<h3 id="cluster-æ¨¡å¼æµ‹è¯•"><a href="#cluster-æ¨¡å¼æµ‹è¯•" class="headerlink" title="cluster æ¨¡å¼æµ‹è¯•"></a>cluster æ¨¡å¼æµ‹è¯•</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark</span><br><span class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 512m --executor-memory 512m --num-executors 1 --total-executor-cores</span><br><span class="line">2 --conf &quot;spark.pyspark.driver.python=/root/anaconda3/bin/python3&quot; --conf</span><br><span class="line">&quot;spark.pyspark.python=/root/anaconda3/bin/python3&quot;</span><br><span class="line">$&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py 3</span><br></pre></td></tr></table></figure>



<p>Author: Chen Qingtao<br>Email: <a href="mailto:&#x31;&#x35;&#x31;&#52;&#51;&#55;&#x39;&#57;&#x30;&#56;&#53;&#x40;&#x71;&#x71;&#46;&#x63;&#111;&#109;">&#x31;&#x35;&#x31;&#52;&#51;&#55;&#x39;&#57;&#x30;&#56;&#53;&#x40;&#x71;&#x71;&#46;&#x63;&#111;&#109;</a></p>

	

	
		<span class="different-posts"><a href="/2022/05/25/Spark-HA-Yarn/" onclick="window.history.go(-1); return false;">â¬…ï¸ Go back </a></span>

	

</article>

	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br />welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>Â© 2022 John Doe | Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> | Theme <a target="_blank" rel="noopener" href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
